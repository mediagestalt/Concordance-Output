{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordance Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concordance is a method of text analysis that is somewhat similar to the generation of word frequency statistics, only the search is expanded to the words that appear on either side of the word under investigation. We call the main search word the 'node' and the words surrounding it the 'span'. A condordance is simply a printed list displaying the sentences or 'context' that the node word appears in. This list is traditonally organized in a 'Key Word in Context' (KWIC) format, which has the node word in the centre of the page. The span can be adjusted, but generally includes about five words on the left and five words on the right of the node. \n",
    "\n",
    "The purpose of generating a concordance output is to allow for manual, but controlled, examination of the word in question. As we will see in this exercise, it becomes very easy to recognize patterns of language use when the text is organized in this way. Further investigation can be conducted by sorting the list of text alphabetically, either on the word just to the left or right of the node word.\n",
    "\n",
    "Generating a concordance output in Python is fairly simple thanks to the `NLTK` module. In this exercise we will generate a concordance output for one of our files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we will import our modules and definitions first. Here we see some new modules: `NLTK`, `codecs`, and `sys`.\n",
    "\n",
    "`NLTK` stands for <a href=\"http://www.nltk.org/book/ch00.html\" target=blank><i>Natural Language Toolkit</i></a>, which facilitates natural language processing in <i>Python</i>. `NLTK` has many functions that support electronic text analysis, including tokenizing, word frequency counters, and for the purposes of this demonstration, concordancers.\n",
    "\n",
    "`codecs` is a module that helps <i>Python</i> read and write text in <span style=\"cursor:help;\" title=\"the industry standard for encoding special characters, like: æ, þ, ß\"><b>Unicode</b></span>, which is a text encoding standard that includes non-alphanumeric characters. We will not be removing the capitalization or punctuation in this exercise, so we're using `codecs` to avoid any errors in reading and printing the file.\n",
    "\n",
    "`sys` is a built-in <i>Python</i> module that allows for the manipulation of the <i>Python</i> <span style=\"cursor:help;\" title=\"the infrastructure required to run programs\"><b>runtime environment</b></span>. Here we will use it to write the output of a program to a text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is where the modules are imported\n",
    "import nltk\n",
    "import sys\n",
    "import codecs\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from os.path import basename\n",
    "\n",
    "# These functions extract the filename\n",
    "\n",
    "def remove_ext(filename):\n",
    "    \"Removes the file extension, such as .txt\"\n",
    "    name, extension = splitext(filename)\n",
    "    return name\n",
    "\n",
    "\n",
    "def remove_dir(filepath):\n",
    "    \"Removes the path from the file name\"\n",
    "    name = basename(filepath)\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename(filepath):\n",
    "    \"Removes the path and file extension from the file name\"\n",
    "    filename = remove_ext(filepath)\n",
    "    name = remove_dir(filename)\n",
    "    return name\n",
    "\n",
    "# This function works on the contents of the file\n",
    "\n",
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = codecs.open(filename, 'r', 'utf-8')\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration we will focus only on one file, the 2013 section of the corpus. As evidenced in the last exercise, <i>Adding Context to Word Frequency Counts</i>, there was a significant increase in the usage of the word `privacy` between 2012 and 2013, which amounted to an increase of about 40%. Here we will take a closer look at 2013 in an attempt to identify any patterns of word use\n",
    "\n",
    "\n",
    "This is a case where cleaning the text may also destroy some of the context. While it is nice to have the numbers line up (in terms of word frequencies vs. number of concordance lines), removing the punctuation and capitalization makes the text harder to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is the path to the file we want to read\n",
    "file = '../Counting Word Frequencies/data/2013.txt'\n",
    "\n",
    "#this calls on a definition from above: it stores the filename as a variable to use later\n",
    "name = get_filename(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reads the file \n",
    "text = read_file(file)\n",
    "#splits the text into a list of individual words\n",
    "words = text.split()\n",
    "#assigns NLTK functionality to the text\n",
    "text = nltk.Text(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will call the function, listing 25 lines from the text.\n",
    "Any other single word could be subsituted here for `privacy`. It can only be one word though, as the last piece of code split the text into single words, so a phrase will break the code. More or less lines can be shown by changing the number beside `lines=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 918 matches:\n",
      "imply unacceptable. That is why the Privacy Commissioner's office was notified.\n",
      " the matter to the attention of the Privacy Commissioner of Canada. I also aske\n",
      "table. That is why we called in the Privacy Commissioner and called in the RCMP\n",
      "able. That is why we brought in the Privacy Commissioner. That is why we brough\n",
      "ese victims and when will they take privacy protection seriously? (1455) Hon. D\n",
      " is why we took steps to inform the Privacy Commissioner of Canada and to bring\n",
      "ystems to make sure that Canadians' privacy is protected. That is why we have e\n",
      " happened. We have also advised the Privacy Commissioner of the situation. We h\n",
      ". Speaker, the government takes the privacy of Canadians extremely seriously. T\n",
      "ely unacceptable. The Office of the Privacy Commissioner has been notified and \n",
      "nment takes extremely seriously the privacy of Canadians and the loss by the de\n",
      "ion. We will continue to do so. The privacy commissioner is investigating this.\n",
      "ed before, the government takes the privacy of Canadians extremely seriously— S\n",
      "mentioned, the government takes the privacy of Canadians extremely seriously. T\n",
      "p greater chances for fraud. As the Privacy Commissioner now conducts her inves\n",
      "g Bob Zimmer Access to Information, Privacy and Ethics Chair: Pierre-Luc Dussea\n",
      "stioned Conservative legislation on privacy concerns, we were accused of standi\n",
      "006. According to the Office of the Privacy Commissioner, this is one of the la\n",
      "he Information Commissioner and the Privacy Commissioner. I will try to delinea\n",
      "the Information Commissioner or the Privacy Commissioner. Each of them are offi\n",
      "ve seen the value of an independent Privacy Commissioner working on behalf of a\n",
      "a government agency. Canada's first Privacy Commissioner, Inger Hansen, was wit\n",
      "ssion at first, and then, under the Privacy Act, became an independent officer \n",
      "tion Commissioner, Auditor General, Privacy Commissioner, we say the Parliament\n",
      "neral, Information Commissioner and Privacy Commissioner are all examples of of\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text.concordance('privacy', lines=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NLTK` module is limited in the amount of processing it can conduct on concordances. It is more useful to output the entire concordance to a text file, which can then be sorted and manipulated in many ways. The following code prints the entire concordance to file. The '79' on line 8 refers to the total number of characters contained in each span, including all letters, punctuation and spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creates a new file that can be written by the print queue\n",
    "fileconcord = codecs.open(name + '_collocates.txt', 'w', 'utf-8')\n",
    "#makes a copy of the empty print queue, so that we can return to it at the end of the function\n",
    "tmpout = sys.stdout\n",
    "#stores the text in the print queue\n",
    "sys.stdout = fileconcord\n",
    "#generates and prints the concordance, the number pertains to the total number of bytes per line\n",
    "text.concordance(\"privacy\", 79, sys.maxsize)\n",
    "#closes the file\n",
    "fileconcord.close()\n",
    "#returns the print queue to an empty state\n",
    "sys.stdout = tmpout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of a sorted concordance. This list is arranged alphabetically on the word to the right of the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sortedConcordance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this list, and the list above, there are distinct patterns of word and phrase use. The unsorted list above contains many examples of \"Office of the Privacy Commissioner\", while the sorted list shows phrases like \"privacy of Canadians\" and \"privacy protection\". The manual examination of a concordance allows a researcher to understand how the node word is used in the context of the corpus, and it can help in the formation of hypotheses about the meaning of the word. \n",
    "\n",
    "In the next exercise we will conduct a more robust statistical examination of the words that accompany the node word, which are known as 'collocates'. Concordance outputs provide a rich context for collocational analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
